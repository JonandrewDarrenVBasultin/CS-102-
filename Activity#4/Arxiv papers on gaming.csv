"","title","author","subject","abstract","meta"
"1","Seamless Human Motion Composition with Blended Positional Encodings","German Barquero, Sergio Escalera, Cristina Palmero","Computer Vision and Pattern Recognition (cs.CV)","Conditional human motion generation is an important topic with many applications in virtual reality, gaming, and robotics. While prior works have focused on generating motion guided by text, music, or scenes, these typically result in isolated motions confined to short durations. Instead, we address the generation of long, continuous sequences guided by a series of varying textual descriptions. In this context, we introduce FlowMDM, the first diffusion-based model that generates seamless Human Motion Compositions (HMC) without any postprocessing or redundant denoising steps. For this, we introduce the Blended Positional Encodings, a technique that leverages both absolute and relative positional encodings in the denoising chain. More specifically, global motion coherence is recovered at the absolute stage, whereas smooth and realistic transitions are built at the relative stage. As a result, we achieve state-of-the-art results in terms of accuracy, realism, and smoothness on the Babel and HumanML3D datasets. FlowMDM excels when trained with only a single description per motion sequence thanks to its Pose-Centric Cross-ATtention, which makes it robust against varying text descriptions at inference time. Finally, to address the limitations of existing HMC metrics, we propose two new metrics: the Peak Jerk and the Area Under the Jerk, to detect abrupt transitions.","Fri, 23 Feb 2024 18:59:40 UTC (15,139 KB)"
"2","MetaStates: An Approach for Representing Human Workers Psychophysiological States in the Industrial Metaverse","Aitor Toichoa Eyam, Jose L. Martinez Lastra","Human-Computer Interaction (cs.HC)","Photo-realistic avatar is a modern term referring to the digital asset that represents a human in computer graphic advance systems such as video games and simulation tools. These avatars utilize the advances in graphic technologies on both software and hardware aspects. While photorealistic avatars are increasingly used in industrial simulations, representing human factors such as human workers internal states, remains a challenge. This article addresses this issue by introducing the concept of MetaStates which are the digitization and representation of the psychophysiological states of a human worker in the digital world. The MetaStates influence the physical representation and performance of a digital human worker while performing a task. To demonstrate this concept the study presents a development of a photorealistic avatar which is integrated into a simulated environment and enhanced with a multi-level graphical representation of different psychophysiological states. This approach represents a major step forward in the use of digital humans for industrial simulations, allowing companies to better leverage the benefits of the Industrial Metaverse in their daily operations and simulations while keeping human workers at the center of the system.","Fri, 23 Feb 2024 14:21:11 UTC (738 KB)"
"3","Shapley Value Based Multi-Agent Reinforcement Learning: Theory, Method and Its Application to Energy Network","Jianhong Wang","Multiagent Systems (cs.MA)","Multi-agent reinforcement learning is an area of rapid advancement in artificial intelligence and machine learning. One of the important questions to be answered is how to conduct credit assignment in a multi-agent system. There have been many schemes designed to conduct credit assignment by multi-agent reinforcement learning algorithms. Although these credit assignment schemes have been proved useful in improving the performance of multi-agent reinforcement learning, most of them are designed heuristically without a rigorous theoretic basis and therefore infeasible to understand how agents cooperate. In this thesis, we aim at investigating the foundation of credit assignment in multi-agent reinforcement learning via cooperative game theory. We first extend a game model called convex game and a payoff distribution scheme called Shapley value in cooperative game theory to Markov decision process, named as Markov convex game and Markov Shapley value respectively. We represent a global reward game as a Markov convex game under the grand coalition. As a result, Markov Shapley value can be reasonably used as a credit assignment scheme in the global reward game. Markov Shapley value possesses the following virtues: (i) efficiency; (ii) identifiability of dummy agents; (iii) reflecting the contribution and (iv) symmetry, which form the fair credit assignment. Based on Markov Shapley value, we propose three multi-agent reinforcement learning algorithms called SHAQ, SQDDPG and SMFPPO. Furthermore, we extend Markov convex game to partial observability to deal with the partially observable problems, named as partially observable Markov convex game. In application, we evaluate SQDDPG and SMFPPO on the real-world problem in energy networks.","Fri, 23 Feb 2024 13:43:15 UTC (58,384 KB)"
"4","Economic and Financial Learning with Artificial Intelligence: A Mixed-Methods Study on ChatGPT","Holger Arndt","Human-Computer Interaction (cs.HC)","In the evolving landscape of digital education, chatbots have emerged as potential game-changers, promising personalized and adaptive learning experiences. This research undertook an in-depth exploration of ChatGPT's potential as an educational tool, focusing on user perceptions, experiences and learning outcomes. Through a mixed-methods approach, a diverse group of 102 participants engaged with ChatGPT, providing insights pre- and postinteraction. The study reveals a notable positive shift in perceptions after exposure, underscoring the efficacy of ChatGPT. However, challenges such as prompting effectiveness and information accuracy emerged as pivotal concerns. Introducing the concept of 'AI-learning-competence', this study lays the groundwork for future research, emphasizing the need for formal training and pedagogical integration of AI tools.","Fri, 23 Feb 2024 11:55:43 UTC (197 KB)"
"5","Open Ad Hoc Teamwork with Cooperative Game Theory","Jianhong Wang, Yang Li, Yuan Zhang, Wei Pan, Samuel Kaski","Multiagent Systems (cs.MA)","Ad hoc teamwork poses a challenging problem, requiring the design of an agent to collaborate with teammates without prior coordination or joint training. Open ad hoc teamwork further complicates this challenge by considering environments with a changing number of teammates, referred to as open teams. The state-of-the-art solution to this problem is graph-based policy learning (GPL), leveraging the generalizability of graph neural networks to handle an unrestricted number of agents and effectively address open teams. GPL's performance is superior to other methods, but its joint Q-value representation presents challenges for interpretation, hindering further development of this research line and applicability. In this paper, we establish a new theory to give an interpretation for the joint Q-value representation employed in GPL, from the perspective of cooperative game theory. Building on our theory, we propose a novel algorithm based on GPL framework, to complement the critical features that facilitate learning, but overlooked in GPL. Through experiments, we demonstrate the correctness of our theory by comparing the performance of the resulting algorithm with GPL in dynamic team compositions.","Fri, 23 Feb 2024 11:04:33 UTC (8,391 KB)"
"6","Mixed strategy approach destabilizes cooperation in finite populations with clustering coefficient","Zehua Si, Zhixue He, Chen Shen, Jun Tanimoto","Populations and Evolution (q-bio.PE)","Evolutionary game theory, encompassing discrete, continuous, and mixed strategies, is pivotal for understanding cooperation dynamics. Discrete strategies involve deterministic actions with a fixed probability of one, whereas continuous strategies employ intermediate probabilities to convey the extent of cooperation and emphasize expected payoffs. Mixed strategies, though akin to continuous ones, calculate immediate payoffs based on the action chosen at a given moment within intermediate probabilities. Although previous research has highlighted the distinct impacts of these strategic approaches on fostering cooperation, the reasons behind the differing levels of cooperation among these approaches have remained somewhat unclear. This study explores how these strategic approaches influence cooperation in the context of the prisoner's dilemma game, particularly in networked populations with varying clustering coefficients. Our research goes beyond existing studies by revealing that the differences in cooperation levels between these strategic approaches are not confined to finite populations; they also depend on the clustering coefficients of these populations. In populations with nonzero clustering coefficients, we observed varying degrees of stable cooperation for each strategic approach across multiple simulations, with mixed strategies showing the most variability, followed by continuous and discrete strategies. However, this variability in cooperation evolution decreased in populations with a clustering coefficient of zero, narrowing the differences in cooperation levels among the strategies. These findings suggest that in more realistic settings, the robustness of cooperation systems may be compromised, as the evolution of cooperation through mixed and continuous strategies introduces a degree of unpredictability.","Fri, 23 Feb 2024 04:34:05 UTC (12,957 KB)"
"7","Analyzing Games in Maker Protocol Part One: A Multi-Agent Influence Diagram Approach Towards Coordination","Abhimanyu Nag, Samrat Gupta, Sudipan Sinha, Arka Datta","Computer Science and Game Theory (cs.GT)","Decentralized Finance (DeFi) ecosystems, exemplified by the Maker Protocol, rely on intricate games to maintain stability and security. Understanding the dynamics of these games is crucial for ensuring the robustness of the system. This motivating research proposes a novel methodology leveraging Multi-Agent Influence Diagrams (MAID), originally proposed by Koller and Milch, to dissect and analyze the games within the Maker stablecoin protocol. By representing users and governance of the Maker protocol as agents and their interactions as edges in a graph, we capture the complex network of influences governing agent behaviors. Furthermore in the upcoming papers, we will show a Nash Equilibrium model to elucidate strategies that promote coordination and enhance economic security within the ecosystem. Through this approach, we aim to motivate the use of this method to introduce a new method of formal verification of game theoretic security in DeFi platforms.","Fri, 23 Feb 2024 01:18:00 UTC (692 KB)"
"8","GenCeption: Evaluate Multimodal LLMs with Unlabeled Unimodal Data","Lele Cao, Valentin Buchner, Zineb Senane, Fangkai Yang","Computation and Language (cs.CL)","Multimodal Large Language Models (MLLMs) are commonly evaluated using costly annotated multimodal benchmarks. However, these benchmarks often struggle to keep pace with the rapidly advancing requirements of MLLM evaluation. We propose GenCeption, a novel and annotation-free MLLM evaluation framework that merely requires unimodal data to assess inter-modality semantic coherence and inversely reflects the models' inclination to hallucinate. Analogous to the popular DrawCeption game, GenCeption initiates with a non-textual sample and undergoes a series of iterative description and generation steps. Semantic drift across iterations is quantified using the GC@T metric. Our empirical findings validate GenCeption's efficacy, showing strong correlations with popular MLLM benchmarking results. GenCeption may be extended to mitigate training data contamination by utilizing ubiquitous, previously unseen unimodal data.","Thu, 22 Feb 2024 21:22:04 UTC (12,335 KB)"
"9","Reinforcement Learning with Elastic Time Steps","Dong Wang, Giovanni Beltrame","Robotics (cs.RO)","Traditional Reinforcement Learning (RL) algorithms are usually applied in robotics to learn controllers that act with a fixed control rate. Given the discrete nature of RL algorithms, they are oblivious to the effects of the choice of control rate: finding the correct control rate can be difficult and mistakes often result in excessive use of computing resources or even lack of convergence. We propose Soft Elastic Actor-Critic (SEAC), a novel off-policy actor-critic algorithm to address this issue. SEAC implements elastic time steps, time steps with a known, variable duration, which allow the agent to change its control frequency to adapt to the situation. In practice, SEAC applies control only when necessary, minimizing computational resources and data usage. We evaluate SEAC's capabilities in simulation in a Newtonian kinematics maze navigation task and on a 3D racing video game, Trackmania. SEAC outperforms the SAC baseline in terms of energy efficiency and overall time management, and most importantly without the need to identify a control frequency for the learned controller. SEAC demonstrated faster and more stable training speeds than SAC, especially at control rates where SAC struggled to converge. We also compared SEAC with a similar approach, the Continuous-Time Continuous-Options (CTCO) model, and SEAC resulted in better task performance. These findings highlight the potential of SEAC for practical, real-world RL applications in robotics.","Thu, 22 Feb 2024 20:49:04 UTC (7,525 KB)"
"10","Implementations of Cooperative Games Under Non-Cooperative Solution Concepts","Justin Chan","Theoretical Economics (econ.TH)","Cooperative games can be distinguished as non-cooperative games in which players can freely sign binding agreements to form coalitions. These coalitions inherit a joint strategy set and seek to maximize collective payoffs. When the payoffs to each coalition under some non-cooperative solution concept coincide with their value in the cooperative game, the cooperative game is said to be implementable and the non-cooperative game its implementation. This paper proves that all strictly superadditive partition function form games are implementable under Nash equilibrium and rationalizability; that all weakly superadditive characteristic function form games are implementable under Nash equilibrium; and that all weakly superadditive partition function form games are implementable under trembling hand perfect equilibrium. Discussion then proceeds on the appropriate choice of non-cooperative solution concept for the implementation.","Thu, 22 Feb 2024 20:27:56 UTC (844 KB)"
